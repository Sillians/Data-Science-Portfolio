---
title: "Exploratory Data Analysis: Numerical Data"
author: "Jane Kathambi"
date: "8 June 2018"
output: 
  html_document:
    keep_md: yes
    theme: united
    number_sections: true
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: yes
      smooth_scroll: yes
---

# Introduction. Data Analysis Overview.


Data analysis is a process of inspecting, cleansing, transforming, and modeling data with the goal of discovering useful information, informing conclusions, and supporting decision-making. 

Three popular data analysis approaches are:

1. Classical
2. Exploratory (EDA)
3. Bayesian

These three approaches are similar in that they all start with a general science/engineering problem and all yield science/engineering conclusions. The difference is the sequence and focus of the intermediate steps as shown below:

* For **classical analysis**, the sequence is:

    + Problem => Data => Model => Analysis => Conclusions

* For **EDA**, the sequence is:

    + Problem => Data => Analysis => Model => Conclusions

* For **Bayesian**, the sequence is:

    + Problem => Data => Model => Prior Distribution => Analysis => Conclusions

Thus for classical analysis, the data collection is followed by the imposition of a model (normality, linearity, etc.) and the analysis, estimation, and testing that follows are focused on the parameters of that model. For EDA, the data collection is not followed by a model imposition; rather it is followed immediately by analysis with a goal of inferring what model would be appropriate. 

Classical Analysis                   | Eda
------------------------------------ | -----------------------------------------
**Imposes models** (both deterministic and probabilistic) on the data. Deterministic models include, for example, regression models and analysis of variance (ANOVA) models. The most common probabilistic model assumes that the errors about the deterministic model are normally distributed--this assumption affects the validity of the ANOVA F tests. | **Does not impose** deterministic or probabilistic models on the data. On the contrary, the EDA approach allows the data to suggest admissible models that best fit the data.
The *focus is on the model*--estimating parameters of the model and generating predicted values from the model. |  The *focus is on the data*--its structure, outliers, and models suggested by the data.
Classical **techniques** are generally **quantitative** in nature. They include ANOVA, t tests, chi-squared tests, and F tests. | EDA **techniques** are generally **graphical**. They include scatter plots, character plots, box plots, histograms, bihistograms, probability plots, residual plots, and mean plots.
Classical techniques serve as the **probabilistic foundation** of science and engineering; the most important characteristic of classical techniques is that they are **rigorous, formal, and "objective"**. | EDA techniques **do not share in that rigor or formality**. EDA techniques make up for that lack of rigor by being **very suggestive, indicative, and insightful about what the appropriate model should be**. EDA techniques are **subjective** and **depend on interpretation which may differ from analyst to analyst**, although experienced analysts commonly arrive at identical conclusions.
Classical estimation techniques have the characteristic of taking all of the data and mapping the data into a few numbers ("estimates"). This is both a virtue and a vice. The virtue is that these few numbers focus on important characteristics (location, variation, etc.) of the population. The vice is that concentrating on these few characteristics can **filter out other characteristics (skewness, tail length, autocorrelation, etc.) of the same population. In this sense there is a loss of information due to this "filtering" process**. | The EDA approach, on the other hand, often makes use of (and shows) all of the available data. In this sense there is **no corresponding loss of information**.
classical tests **depend on underlying assumptions** (e.g., normality), and hence the validity of the test conclusions becomes dependent on the validity of the underlying assumptions. Worse yet, the exact underlying assumptions may be unknown to the analyst, or if known, untested. | Many EDA techniques make **little or no assumptions--they present and show the data--all of the data--as is, with fewer encumbering assumptions**

In this post, we'll work with the cars dataset, which records characteristics on all of the new models of cars for sale in the US in a certain year. We will investigate the distribution of mileage across a categorial variable, but before we get there, let us familiarize ourselves with the cars dataset.

# Loading the Required Libraries


Let us load the required libraries

```{r}
library(data.table)
library(ggplot2)
library(dplyr)
```


# Loading the cars data


We will use fread() of the data.table package 

```{r}
cars<-fread("data/cars.csv")
```


# EDA of the cars dataset

## Initial exploration of the cars data set

```{r}
# View the size of the data and the variable types
glimpse(cars)

```

The cars data set has a mixture of data types including, chr, logical, dbl, and int.
## Distribution of two variables

### Faceted histogram

We are going to investigate the distribution of mileage i.e *city_mpg* across a categorial variable, _suv_

Mileage i.e *city_mpg* is a numerical variable and since numerical variables are continous we will investigate its distribution using a histogram.

We will plot a histogram of *city_mpg* facetted by logical variable _suv_ that indicates whether the car is an SUV or not. 

Categorical variables e.g logical variables, gender e.t.c are used to facet plots i.e we can facet a plot by any categorical variable using facet_wrap().


```{r}
# Create faceted histogram
ggplot(cars, aes(x = city_mpg)) +
  geom_histogram() +
  facet_wrap(~ suv)
```

#### Interpreting the facetted histogram

1. The non SUVs are more than the SUVs.
2. The non SUVs make higher mileage than the SUVs.
3. The non SUVs have more variablity than the SUVs.
4. It gives us a warning that there are 14 missing values which have been omitted by the plot.

### Boxplots 

The mileage of a car tends to be associated with the size of its engine (as measured by the number of cylinders). To explore the relationship between these two variables, we could stick to using histograms, but in section we'll try  the box plot and in the next section the density plot.

A quick look at unique(cars$ncyl) i.e number of cylinders shows that there are more possible levels of ncyl than you might think. Here, we will restrict our attention to the most common levels by filtering the cars data set with the most common levels.

Which are the most common levels?  We will use the table function to calculate this.

```{r}
# Let us look at the unique levels of the variable ncyl. There are 8 unique levels.
unique(cars$ncyl)

#To show the most common levels? It is levels 4,6 and 8.
table(cars$ncyl)

```

**Interpreting the results:**

1. There are 8 unique levels. i.e -1, 3, 4, 5, 6, 8, 10, 12
2. The most common levels are 4,6,8. This means that majority of cars have 4, or 6, or 8 number of cylinders.


Let us now **filter cars to include only cars with 4, 6, or 8 cylinders** and save the result as common_cyl. We will use the %in% operator.


```{r}
# Filter cars with 4, 6, 8 cylinders
common_cyl= cars %>%
            filter(ncyl %in% c(4,6,8) )

# confim if the filtering has occurred
unique(common_cyl$ncyl)
```


Let us now create side-by-side box plots of city_mpg separated out by ncyl

```{r}
# Create box plots of city mpg by ncyl
ggplot(common_cyl, aes(x = as.factor(ncyl), y = city_mpg)) +
  geom_boxplot()

```


**Interpreting the box plot:**

1. City miles decrease with increase in number of cylinders.
2. There are outliers as shown by the black dots.
3. The miles of the cars that have 6 cylnders do not vary much. However, the miles of the cars with 8 cylinders vary more and those with 4 cylinders vary most.
4. The longer upper whisker of the first box plot, shows that majority of cars with 4 cylinders have their mpg varying a lot, however the shorter whiskers of cars with 6 and 8 cylinders tells us that their mpg does not vary much and it tends to center around the average.
5. Skew of the data, Skew refers to the asymmetry of your data: 

    + If you look at cars with 6 cylinders, the box and whiskers are pretty even on either side of the median. 
    
    + However, the distribution of cars with 4 cylinders is skewed towards the lower end since majority of these cars are concentrated on the upper end. This means that majority of cars with 4 cylinders have relatively high mileage.
    
    + Similarly, the distribution of cars with 8 cylinders is heavily skewed towards the lower end since majority of these cars are concentrated on the upper end. This means that majority of cars with 8 cylinders have a mileage of around 17.

NB: Skewness is only considered in the case of continous variables not categorical variables. NB. city_mpg is continous.

### Density Plot
A Density Plot visualises the distribution of data over a continuous interval or time period. This chart is a variation of a Histogram that uses kernel smoothing to plot values, allowing for smoother distributions by smoothing out the noise. The peaks of a Density Plot help display where values are concentrated over the interval.

An advantage Density Plots have over Histograms is that they're better at determining the distribution shape because they're not affected by the number of bins used (each bar used in a typical histogram). A Histogram comprising of only 4 bins wouldn't produce a distinguishable enough shape of distribution as a 20-bin Histogram would. However, with Density Plots, this isn't an issue.

Therefore, Kernal density plots are usually a much more effective way to view the distribution of a variable.

Let us now create overlaid density plots of city_mpg colored by ncyl

```{r}
# Create overlaid density plots for same data
ggplot(common_cyl, aes(x = city_mpg, fill = as.factor(ncyl))) +
  geom_density(alpha = .3)
```

#### Interpreting the density plot

1. The highest mileage cars have 4 cylinders.
2. The typical 4 cylinder car gets better mileage than the typical 6 cylinder car, which gets better mileage than the typical 8 cylinder car.
3. Most of the 4 cylinder cars get better mileage than even the most efficient 8 cylinder cars.
4. The variability in mileage of 8 cylinder cars seem much smaller than that of 4 cylinder cars.
5. Similarly, the variability in mileage of 6 cylinder cars seem much smaller than that of 4 cylinder cars.

## Distribution of one varriable

We will now look at the distribution of a single varaible.

## Marginal and conditional histograms

We are going to work with a new variable: horsepwr. The goal is to get a sense of the marginal distribution of this variable and then compare it to the distribution of horsepower conditional on the price of the car being less than $25,000.

We'll be making two plots using the "data pipeline" paradigm of dplyr, where you start with the raw data and end with the plot.

### Marginal Histogram

Let us now create a histogram of the distribution of horsepwr across all cars (across all cars explains the marginal name) and add an appropriate title.

```{r}
cars%>%
  ggplot(aes(x=horsepwr))+
  geom_histogram()+
  ggtitle("A histogram of the distribution of horsepwr")
```
#### Interpreting the marginal histogram

1. Cars with around 275 horsepower are more common than cars with around 300 horsepower.
2. Generally the distribution on horse power varies a lot.

### Conditional Histograms

We will now create a second histogram of the distribution of horsepower, but only for those cars that have an msrp(manufacturer's suggested retail price) less than $25,000. We will keep the limits of the x-axis so that they're similar to that of the first plot, and add a descriptive title.

```{r}
cars%>%
  filter(msrp<25000)%>%
  ggplot(aes(x=horsepwr))+
  geom_histogram()+
  xlim(c(90, 550)) +
  ggtitle("The distribution of horsepwr for cars with an msrp less than $25,000")
```

#### Interpreting the conditional histogram

1. The highest horsepower car in the less expensive range has just under 250 horsepower.
2. Cars in the less expensive range and have around 150 horsepower are the most common.

### Binwidths

It's a good idea to see how things change when you alter the binwidth  of histograms. 

The binwidth determines how smooth your distribution will appear: the smaller the binwidth, the more jagged your distribution becomes.

It's good practice to consider several binwidths in order to **detect different types of structure in your data**.

Let us create the following three plots, adding a title to each to indicate the binwidth used:

1. A histogram of horsepower (i.e. horsepwr) with a binwidth of 3.
2. A second histogram of horsepower with a binwidth of 30.
3. A third histogram of horsepower with a binwidth of 60.

```{r}
# Create hist of horsepwr with binwidth of 3
cars %>%
  ggplot(aes(horsepwr)) +
  geom_histogram(binwidth = 3) +
  ggtitle("Plot A: A histogram of horsepwr with binwidth of 3")

# Create hist of horsepwr with binwidth of 30
cars %>%
  ggplot(aes(horsepwr)) +
  geom_histogram(binwidth = 30) +
  ggtitle("Plot B: A histogram of horsepwr with binwidth of 30")

# Create hist of horsepwr with binwidth of 60
cars %>%
  ggplot(aes(horsepwr)) +
  geom_histogram(binwidth = 60) +
  ggtitle("Plot C: A histogram of horsepwr with binwidth of 60")
```

#### Binwidths Interpretation

1. Plot A is the only histogram that shows the count for cars with exactly 200 and 300 horsepower i.e Plot A is the only histogram that shows the count for cars with exactly 200 and 300 horsepower.

## Boxplots

### Box plots for outliers

In addition to indicating the center and spread of a distribution, a box plot provides a graphical means to detect outliers. 

We will apply this method to the msrp column (manufacturer's suggested retail price) to detect if there are unusually expensive or cheap cars:

1. Construct a box plot of msrp. Check out for the point(msrp) where the outliers beging uccuring.

2. Exclude the largest 3-5 outliers by filtering the rows to retain cars less than $100,000. Save this reduced dataset as cars_no_out.

3. Construct a similar box plot of msrp using this reduced dataset. Compare the two plots.

```{r}
# Construct box plot of msrp
cars %>%
  ggplot(aes(x = 1, y = msrp)) +
  geom_boxplot()

# Exclude outliers from data
cars_no_out <- cars %>%
  filter(msrp<100000)

# Construct box plot of msrp using the reduced dataset
cars_no_out %>%
  ggplot(aes(x = 1, y = msrp)) +
  geom_boxplot()
```


**Comparing the two plots**

The precision of the second plot has increased since some of the outliers have been removed.


## Plot selection

Consider two other columns in the cars dataset: city_mpg and width. Which is the most appropriate plot for displaying the important features of their distributions? Remember, both density plots and box plots display the central tendency and spread of the data, but the box plot is more robust to outliers. So for the variable that has a much wider range with its outliers, it's best to display its distribution as a box plot.

We will now use density plots and box plots to construct the following visualizations. For each variable, we will try both plots and select the one that is better at capturing the important structure.

1. Display the distribution of city_mpg. Vote
2. Display the distribution of width. Vote

**Display the distribution of city_mpg**

```{r}
# Create a box plot of city_mpg
cars %>%
  ggplot(aes(x=1, y=city_mpg) ) +
  geom_boxplot()

# Create density plot of city_mpg
cars %>% 
  ggplot(aes(x=city_mpg)) +
  geom_density()
```

**VOTE**
Because the city_mpg variable has a much wider range with its outliers, it's best to display its distribution as a box plot. So for this variable the box plot wins.

**Display the distribution of width**

```{r}
# Create a box plot of width
cars %>%
  ggplot(aes(x=1, y=width) ) +
  geom_boxplot()

# Create density plot of width
cars %>% 
  ggplot(aes(x=width)) +
  geom_density()
```

**VOTE**
The boxplot doesnt show much about width apart from telling us that it is evenly distributed and has two outliers. However the density plot shows how the distribution is a multimodal one with three modes. This tells us that majority of the observations/cars have widths which fall within the three common widths approximately 68, 72 and 78.
So for width we chose the density plot since it tells us more about the distribution.

## Visualization in higher dimensions

### 3 variable plot
Faceting is a valuable technique for looking at several conditional distributions at the same time. If the faceted distributions are laid out in a grid, you can consider the association between a variable and two others, one on the rows of the grid and the other on the columns.

We will use the common_cyl, which we created to contain only cars with 4, 6, or 8 cylinder, to create a histogram of _**hwy_mpg**_ faceted on both _**ncyl**_ and _**suv**_.
We will also add a title to this plot to indicate what variables are being faceted on.

```{r}
# Facet hists using hwy mileage and ncyl
common_cyl %>%
  ggplot(aes(x =hwy_mpg)) +
  geom_histogram() +
  facet_grid(ncyl ~ suv, labeller = label_both)
```


#### Interpreting the 3 var plot

1. Across both SUVs and non-SUVs, mileage tends to decrease as the number of cylinders increases.
2.There are more non-suv cars than suv cars across all cylinder types.


# Conclusion

## Histogram versus boxplot

1. The fact that box plots provide more of a summary of a distribution can also be seen as an advantage in certain cases. Sometimes when we're comparing distributions we don't care about overall shape, but rather where the distributions lie with regard to one another. Plotting the quantiles side by side can be a useful way of doing this without distracting us with other details that we may not care about. So, boxplots are better for comparing distributions than histograms!
  
 Distribution is basically the spread of a dataset. For example, the median of a dataset is the half-way point. Half of the values are less than the median, and the other half are greater than.

2. . Boxplots are Robust with outliers too.

## Histogram versus density plot

Histograms work very well with fewer data points of a variable, and one wants to make comparisons with groups of another variable. 
However they will be cluttered when the data points increase since at each data point they show bins for every category of the variable that is being compared with.

So density plots are better as they produce a single line for every category of the variable being used for comparisons.

## Density plots versus box plots

1. Box plots are more robust with missing data.
2. Density plots are better for plotting a single variable.

## Multivariate data sets: Histogram versus density plots

1. If the data points of the variables are relatively few Use histogram facetted with the other varaibles, if the variables to facet with are many use the color aesthetic instead.

2. However if the data points of the variables are many use a density plot with the color aesthetic.































