---
title: "Exploratory Data Analysis: Categorical Data"
author: "Jane Kathambi"
date: "8 June 2018"
output: 
  html_document:
    keep_md: yes
    theme: united
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: yes
      smooth_scroll: yes
---

# Introduction. Data Analysis Overview.
Data analysis is a process of inspecting, cleansing, transforming, and modeling data with the goal of discovering useful information, informing conclusions, and supporting decision-making. 

Three popular data analysis approaches are:

1. Classical
2. Exploratory (EDA)
3. Bayesian

These three approaches are similar in that they all start with a general science/engineering problem and all yield science/engineering conclusions. The difference is the sequence and focus of the intermediate steps as shown below:

* For **classical analysis**, the sequence is:

    + Problem => Data => Model => Analysis => Conclusions

* For **EDA**, the sequence is:

    + Problem => Data => Analysis => Model => Conclusions

* For **Bayesian**, the sequence is:

    + Problem => Data => Model => Prior Distribution => Analysis => Conclusions

Thus for classical analysis, the data collection is followed by the imposition of a model (normality, linearity, etc.) and the analysis, estimation, and testing that follows are focused on the parameters of that model. For EDA, the data collection is not followed by a model imposition; rather it is followed immediately by analysis with a goal of inferring what model would be appropriate. 

Classical Analysis                   | Eda
------------------------------------ | -----------------------------------------
**Imposes models** (both deterministic and probabilistic) on the data. Deterministic models include, for example, regression models and analysis of variance (ANOVA) models. The most common probabilistic model assumes that the errors about the deterministic model are normally distributed--this assumption affects the validity of the ANOVA F tests. | **Does not impose** deterministic or probabilistic models on the data. On the contrary, the EDA approach allows the data to suggest admissible models that best fit the data.
The *focus is on the model*--estimating parameters of the model and generating predicted values from the model. |  The *focus is on the data*--its structure, outliers, and models suggested by the data.
Classical **techniques** are generally **quantitative** in nature. They include ANOVA, t tests, chi-squared tests, and F tests. | EDA **techniques** are generally **graphical**. They include scatter plots, character plots, box plots, histograms, bihistograms, probability plots, residual plots, and mean plots.
Classical techniques serve as the **probabilistic foundation** of science and engineering; the most important characteristic of classical techniques is that they are **rigorous, formal, and "objective"**. | EDA techniques **do not share in that rigor or formality**. EDA techniques make up for that lack of rigor by being **very suggestive, indicative, and insightful about what the appropriate model should be**. EDA techniques are **subjective** and **depend on interpretation which may differ from analyst to analyst**, although experienced analysts commonly arrive at identical conclusions.
Classical estimation techniques have the characteristic of taking all of the data and mapping the data into a few numbers ("estimates"). This is both a virtue and a vice. The virtue is that these few numbers focus on important characteristics (location, variation, etc.) of the population. The vice is that concentrating on these few characteristics can **filter out other characteristics (skewness, tail length, autocorrelation, etc.) of the same population. In this sense there is a loss of information due to this "filtering" process**. | The EDA approach, on the other hand, often makes use of (and shows) all of the available data. In this sense there is **no corresponding loss of information**.
classical tests **depend on underlying assumptions** (e.g., normality), and hence the validity of the test conclusions becomes dependent on the validity of the underlying assumptions. Worse yet, the exact underlying assumptions may be unknown to the analyst, or if known, untested. | Many EDA techniques make **little or no assumptions--they present and show the data--all of the data--as is, with fewer encumbering assumptions**

With that in mind let us now dive into EDA of Categorical Data. Remember that EDA is graphical and bar charts are good for categorical data. We can also use contingency tables. A contingency table is a table showing the distribution of one variable in rows and another in columns, used to study the correlation between the two variables. It is a useful way to represent the total counts of observations that fall into each combination of the levels of categorical variables.

We will work with the comics data set.This is a collection of characteristics on all of the superheroes created by Marvel and DC comics in the last 80 years.

# Loading the Required Libraries

Let us load the required libraries

```{r}
library(ggplot2)
library(dplyr)
```

# Loading the comics data

We will use read.csv() of the utils package i.e base r package.

```{r}
comics<-read.csv("data/comics.csv")
```


# EDA of the Comics dataset

## Initial exploration of the comics data set

```{r}
# Print the first rows of the data
comics

#view the variable names of comics
names(comics)

#view the internal structure of comics
glimpse(comics)

# Check levels of align
levels(comics$align)

# Check the levels of gender
levels(comics$gender)
```

## The contingency table
As said earlier a contingency table is a useful way to represent the total counts of observations that fall into each combination of the levels of categorical variables.

We will show the cotingency table of comics alignment versus gender. Save it as contab.

```{r}
# Create a 2-way contingency table: contab
contab<-table(comics$align,comics$gender)

#show contab
contab
```

