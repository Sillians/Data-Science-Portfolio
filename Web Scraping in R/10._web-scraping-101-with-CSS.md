---
title: "Web scraping 101: with CSS"
author: "Jane Kathambi"
date: "11 July 2018"
output: 
  html_document:
    keep_md: yes
    theme: united
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: yes
      smooth_scroll: yes
---

# Web scraping 101 with CSS

What if you dont have a server API and you want to scrape data? You use rvest read_html(url) function to obtain the webpage in xml format. We then later use rvest functions (html_node(), html_text()) to scrape the data.

I case we use an API to read in data we tell it to return the xml format.

The first step with web scraping is actually reading the HTML in. This can be done with a function from xml2, which is imported by rvest - read_html(). 

This accepts a single URL, and returns a big blob of XML that we can use further on.

We're going to experiment with that by grabbing Hadley Wickham's wikipedia page, with rvest, and then printing it just to see what the structure looks like.

# Using CSS to scrape nodes

CSS is a way to add design information to HTML, that instructs the browser on how to display the content. You can leverage these design instructions to identify content on the page.

You've already used html_node(), but it's more common with CSS selectors to use html_nodes() since you'll often want more than one node returned. Both functions allow you to specify a css argument to use a CSS selector, instead of specifying the xpath argument.

We use the html_nodes() function with two arguments:
1. The xml document/data
2. The css selector

NB: As already said you can also use html_node() but it's more common with CSS selectors to use html_nodes() since you'll often want more than one node returned.

# Load the required libraries


```r
library(rvest)
```

```
## Warning: package 'rvest' was built under R version 3.5.1
```

```
## Loading required package: xml2
```

```
## Warning: package 'xml2' was built under R version 3.5.1
```

# Hadley Wickham's wikipedia page

Let us now grab Hadley Wickham's wikipedia page, with rvest, and then printing it just to see what the structure looks like.


```r
# Hadley Wickham's Wikipedia page
test_url <- "https://en.wikipedia.org/wiki/Hadley_Wickham"

# Read the URL stored as "test_url" with read_html()
test_xml <- read_html(test_url)

# Print test_xml
test_xml
```

```
## {xml_document}
## <html class="client-nojs" lang="en" dir="ltr">
## [1] <head>\n<meta http-equiv="Content-Type" content="text/html; charset= ...
## [2] <body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-sub ...
```

# Extracting nodes by css selectors
We use the html_nodes() function with two arguments:
1. The xml document/data
2. The css selector

NB: As already said you can also use html_node() but it's more common with CSS selectors to use html_nodes() since you'll often want more than one node returned.

Use the CSS selector "table" to select all elements that are a table tag.

# How to use css selectors
To select elements with a certain tag, you simply use the tag name.
To select elements with a certain class, you add a . in front of the class name. To select an element based on its id, you add a # in front of the id name.



```r
# Select the table elements
html_nodes(test_xml, css = 'table')
```

```
## {xml_nodeset (2)}
## [1] <table class="infobox biography vcard" style="width:22em"><tbody>\n< ...
## [2] <table class="nowraplinks hlist navbox-inner" style="border-spacing: ...
```

Use the CSS selector ".infobox" to select all elements that have the attribute class = "infobox".


```r
# Select elements with class = "infobox"
html_nodes(test_xml, css = ".infobox")
```

```
## {xml_nodeset (1)}
## [1] <table class="infobox biography vcard" style="width:22em"><tbody>\n< ...
```

Use the CSS selector "#firstHeading" to select all elements that have the attribute id = "firstHeading".


```r
# Select elements with id = "firstHeading"
html_nodes(test_xml, css = "#firstHeading")
```

```
## {xml_nodeset (1)}
## [1] <h1 id="firstHeading" class="firstHeading" lang="en">Hadley Wickham< ...
```


# Scraping names

Once you've selected an element with a CSS selector, you can get the element tag name just like you did with XPATH selectors, with html_name(). Try it!



```r
# Extract element with class infobox
infobox_element <- html_nodes(test_xml, css = '.infobox')

# Get tag name of infobox_element
element_name1 <- html_name(infobox_element)

# Print element_name
element_name1
```

```
## [1] "table"
```

```r
#also
# Select the table elements
table_element=html_nodes(test_xml, css = 'table')

# Get tag name of table_element
element_name2 <- html_name(table_element)

# Print element_name
element_name2
```

```
## [1] "table" "table"
```

```r
# also
# Select elements with id = "firstHeading"
firstHeading_element=html_nodes(test_xml, css = "#firstHeading")

# Get tag name of firstHeading_element
element_name3 <- html_name(firstHeading_element)

# Print element_name
element_name3
```

```
## [1] "h1"
```


# Scraping text
Of course you can get the contents of a node extracted using a CSS selector too, with html_text()

Let us extract the text of the infobox_element.

Use html_node() to extract the element from infobox_element with the CSS class fn


```r
# Extract element with class fn
page_name<-html_node(x=infobox_element, css='.fn')
page_name
```

```
## {xml_nodeset (1)}
## [1] <span class="fn">Hadley Wickham</span>
```

```r
# NB: page_name is an element or node
```

Use html_text() to extract the contents of page_name


```r
# Get contents of page_name
page_title<-html_text(page_name)

# Print page_title
page_title
```

```
## [1] "Hadley Wickham"
```

# Test: CSS web scraping
Take a look at the chunk of HTML being read into test:

test <- read_html('
   <h1 class = "main">Hello world!</h1>
   ')
How would you extract the text Hello world! using rvest and CSS selectors?

 Answer: html_text(html_node(test, css = ".main"))

